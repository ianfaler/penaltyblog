{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d49ebd83",
   "metadata": {},
   "source": [
    "# Utility, Inspection, & Interoperability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5074ba",
   "metadata": {},
   "source": [
    "Beyond transforming data, `Flow` provides several utility methods to help you inspect your data stream, understand its contents, and integrate `Flow` pipelines with other Python libraries and custom functions.\n",
    "\n",
    "## Inspecting Your Flow\n",
    "\n",
    "Beyond transforming data, `Flow` provides several introspection tools to help you peek into the stream, check schema, count records, or safely debug your pipeline—without accidentally consuming your data.\n",
    "\n",
    "Under the hood, many of these methods use `itertools.tee()` to preserve the internal state of the stream so that even destructive-looking operations like `.first()` or `.collect()` won't discard records unless explicitly intended.\n",
    "\n",
    "## Peek at the First Record: `.first()`\n",
    "\n",
    "Returns the first record in the stream without consuming it. If the `Flow` is empty, returns `None`.\n",
    "\n",
    "```python\n",
    "first_event = events_flow.first()\n",
    "```\n",
    "\n",
    "This is great for sampling structure or validating input without altering the pipeline.\n",
    "\n",
    "## Grab the Final Record: `.last()`\n",
    "\n",
    "Returns the last record in the stream. Since this requires scanning the full iterator, it will consume the flow. Use `.cache()` if you need to call `.last()` and still reuse the data.\n",
    "\n",
    "```python\n",
    "last_event = events_flow.last()\n",
    "```\n",
    "\n",
    "## Is There Anything in Here? `.is_empty()`\n",
    "\n",
    "Checks whether the stream is empty. Uses `tee()` to avoid losing the first record if present.\n",
    "\n",
    "```python\n",
    "if events_flow.is_empty():\n",
    "    print(\"No events found.\")\n",
    "```\n",
    "\n",
    "## Discover All Field Names: `.keys(limit=None)`\n",
    "\n",
    "Returns the union of keys across records, optionally limited to the first `n`. Uses `tee()` internally to preserve stream state.\n",
    "\n",
    "```python\n",
    "events_flow.keys(limit=10)  \n",
    "events_flow.keys()          \n",
    "```\n",
    "\n",
    "This is useful for understanding schema drift in semi-structured JSON.\n",
    "\n",
    "## Count the Records: `.len()`\n",
    "\n",
    "Calling `.len()` materializes the stream, counting all records. This consumes the `Flow`, so only use when needed. To safely inspect and reuse later, call `.cache()` first.\n",
    "\n",
    "```python\n",
    "flow = Flow(data).cache()\n",
    "print(len(flow))  # Safe and repeatable\n",
    "```\n",
    "\n",
    "## A Helpful Summary: `repr(flow)`\n",
    "\n",
    "Printing a Flow shows a preview with sample records and an estimated count:\n",
    "\n",
    "```python\n",
    "print(flow)\n",
    "# <Penaltyblog Flow | n≈? | sample=[..., ...]>\n",
    "```\n",
    "\n",
    "If `len()` has been called (or `flow.cache()` used), the count will be included accurately."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16576321",
   "metadata": {},
   "source": [
    "## Materializing the Flow\n",
    "\n",
    "## Materialize All Records: `.collect()`\n",
    "\n",
    "The most common way to materialize your data is by calling `.collect()`, which runs the full pipeline and returns a list of dictionaries.\n",
    "\n",
    "```python\n",
    "records = events_flow.filter(...).assign(...).collect()\n",
    "```\n",
    "\n",
    "Behind the scenes, `.collect()` uses `itertools.tee()` to ensure the original `Flow` remains usable even after materialization. So you can safely call `.collect()` multiple times if needed - at the cost of some internal buffering.\n",
    "\n",
    "This is ideal when you're ready to work with all records at once, or when handing data off to another tool (e.g., pandas).\n",
    "\n",
    "## Insert Custom Logic Anywhere: `.pipe()`\n",
    "\n",
    "Use `.pipe()` to insert your own logic into a `Flow` chain - this is perfect for custom filtering, integration with other libraries, or building reusable transformations.\n",
    "\n",
    "```python\n",
    "def process_shots(flow, min_xg=0.25):\n",
    "    return (\n",
    "        flow\n",
    "        .filter(lambda r: r.get(\"type_name\") == \"Shot\" and r.get(\"shot_xg\", 0) >= min_xg)\n",
    "        .assign(is_high_xg=True)\n",
    "    )\n",
    "\n",
    "# Chain your custom step using .pipe\n",
    "high_xg = Flow(events).pipe(process_shots, min_xg=0.3)\n",
    "results = high_xg.select(\"player_name\", \"shot_xg\", \"is_high_xg\").collect()\n",
    "```\n",
    "\n",
    "`.pipe()` is chainable - your function should return a `Flow` if you want to keep chaining. But it can also return any result (like a DataFrame, plot, or summary) as a final output.\n",
    "\n",
    "## Using `.pipe()` for External Libraries (e.g. pandas)\n",
    "\n",
    "You can use `.pipe()` to bridge Flow with pandas or other tools:\n",
    "\n",
    "```python\n",
    "def team_summary(flow):\n",
    "    df = flow.to_pandas()\n",
    "    return df.groupby(\"team_name\")[\"shot_xg\"].agg([\"sum\", \"mean\", \"count\"])\n",
    "\n",
    "summary_df = (\n",
    "    Flow(events)\n",
    "    .filter(lambda r: r.get(\"type_name\") == \"Shot\")\n",
    "    .pipe(team_summary)\n",
    ")\n",
    "```\n",
    "\n",
    "This pattern keeps your pipeline modular and composable.\n",
    "\n",
    "## Interoperability with pandas\n",
    "\n",
    "Flow integrates cleanly with pandas - great for advanced analysis, plotting, or export.\n",
    "\n",
    "`.to_pandas()`: Convert to a DataFrame\n",
    "\n",
    "Use `.to_pandas()` to convert a `Flow` into a `pandas.DataFrame`. This materializes the full stream.\n",
    "\n",
    "```python\n",
    "df = Flow(events).filter(lambda r: r.get(\"period\") == 1).to_pandas()\n",
    "print(df.head())\n",
    "```\n",
    "\n",
    "## Quick Summary Stats: `.describe()`\n",
    "\n",
    "This method materializes the data into a DataFrame and returns the result of `DataFrame.describe()`.\n",
    "\n",
    "```python\n",
    "Flow(events)\n",
    "  .select(\"shot_xg\", \"location_x\", \"location_y\")\n",
    "  .describe()\n",
    "```\n",
    "\n",
    "You can customize the output by passing pandas-style arguments:\n",
    "\n",
    "```python\n",
    "# Show object/string field summaries\n",
    "Flow(events).describe(include=\"object\")\n",
    "\n",
    "# Change percentiles\n",
    "Flow(events).describe(percentiles=(0.1, 0.5, 0.9))\n",
    "```\n",
    "\n",
    "These utilities make it easy to blend the simplicity of `Flow` with the power of pandas, and to inspect or export your data as needed - without losing the benefits of lazy, composable pipelines."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
