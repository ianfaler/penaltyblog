{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1053f53",
   "metadata": {},
   "source": [
    "# Best Practices, Performance, & Troubleshooting\n",
    "\n",
    "**Flow** is designed to help you write clear, efficient pipelines - especially for semi-structured, JSON-like data. This chapter covers key patterns and tips to help you work confidently with large datasets, avoid common pitfalls, and get predictable performance.\n",
    "\n",
    "## Understand Flow‚Äôs Single-Pass Nature\n",
    "Flow operates as a lazy, streaming pipeline. Each operation defines a transformation - but nothing happens until you materialize the flow:\n",
    "\n",
    "```python\n",
    "flow = Flow(data).filter(...).assign(...)\n",
    "```\n",
    "\n",
    "At this point, nothing has run yet.\n",
    "\n",
    "Only when you call `.collect()`, `.to_pandas()`, `.to_jsonl()`, or iterate over the flow does the processing begin and the stream is **consumed**.\n",
    "\n",
    "## Want to Reuse a Flow? Use `.materialize()`\n",
    "\n",
    "Most `Flow` operations are destructive - they consume the data.\n",
    "\n",
    "If you need to inspect or use a `Flow` multiple times, call `.materialize()`:\n",
    "\n",
    "```python\n",
    "cleaned = Flow.from_jsonl(\"events.jsonl\").filter(...).assign(...)\n",
    "\n",
    "forked = cleaned.materialize()\n",
    "\n",
    "summary = forked.group_by(\"team\").summary(...)\n",
    "shots = forked.filter(lambda r: r[\"type_name\"] == \"Shot\")\n",
    "```\n",
    "\n",
    "‚úÖ This converts the stream into a backed list, making the resulting `Flow` safe for reuse.\n",
    "\n",
    "## Avoid Internal Buffering Confusion\n",
    "\n",
    "- All flows are single-pass\n",
    "- All inspection methods (`.first()`, `.keys()`, `.last()`, `len()`, etc.) consume the flow\n",
    "- If you need to reuse, call `.materialize()` before inspecting\n",
    "\n",
    "Example:\n",
    "\n",
    "```python\n",
    "flow = Flow.from_jsonl(\"match.jsonl\")\n",
    "\n",
    "flow.first()  # ‚Üê Consumes the stream!\n",
    "flow.collect()  # ‚Üê Now returns nothing (already consumed)\n",
    "\n",
    "# Correct usage\n",
    "flow = Flow.from_jsonl(\"match.jsonl\").materialize()\n",
    "flow.first()  # Safe\n",
    "flow.collect()  # Still safe\n",
    "```\n",
    "\n",
    "## Know Which Operations Consume the Stream\n",
    "\n",
    "The following consume the entire flow and return a result:\n",
    "\n",
    "| Operation                   | Description           |\n",
    "| --------------------------- | --------------------- |\n",
    "| `.collect()`                | List of records       |\n",
    "| `.to_pandas()`              | Pandas DataFrame      |\n",
    "| `.to_json()`, `.to_jsonl()` | JSON serialization    |\n",
    "| `.group_by()`, `.summary()` | Aggregations          |\n",
    "| `.sort()`, `.row_number()`  | Sorting, ranking      |\n",
    "| `.take_last()`, `.last()`   | Back-of-stream access |\n",
    "| `len(flow)`                 | Count of records      |\n",
    "| `.keys()`                   | Union of fields       |\n",
    "| `.describe()`               | Stats via pandas      |\n",
    "\n",
    "üí° If you're calling any of these, the original stream is gone unless you `.materialize()` beforehand.\n",
    "\n",
    "## Recommended Patterns\n",
    "\n",
    "| Situation                        | Recommendation                                |\n",
    "| -------------------------------- | --------------------------------------------- |\n",
    "| One-off pipeline                 | `.filter(...).assign(...).collect()`          |\n",
    "| Reuse across steps               | `.materialize()` once early                   |\n",
    "| Branching into multiple analyses | `.materialize()` then fork                    |\n",
    "| Large files                      | Use `.from_jsonl()` and avoid `.sort()` early |\n",
    "| Exploring schema                 | `.head(n).collect()` for shallow preview      |\n",
    "| Debugging steps                  | Use `.pipe()` or `.head()` to inspect         |\n",
    "| Avoiding surprises               | Always materialize before reuse               |\n",
    "\n",
    "## Debugging Pipelines\n",
    "\n",
    "### Break Up Long Chains\n",
    "\n",
    "Split pipelines into small, readable steps:\n",
    "\n",
    "```python\n",
    "step1 = flow.filter(...)\n",
    "print(step1.head(3).collect())  # Inspect safely\n",
    "step2 = step1.assign(...)\n",
    "```\n",
    "\n",
    "### Use `.pipe()` for Debug Hooks\n",
    "\n",
    "```python\n",
    "def peek(flow):\n",
    "    print(flow.head(3).collect())\n",
    "    return flow\n",
    "\n",
    "Flow(events).filter(...).pipe(peek).assign(...)\n",
    "```\n",
    "\n",
    "Great for inspecting intermediate state without disrupting your pipeline logic.\n",
    "\n",
    "## When Not to Use Flow\n",
    "\n",
    "`Flow` is built for in-memory processing of structured/semi-structured records. Consider alternatives if:\n",
    "\n",
    "- You need true SQL-style joins across many large tables\n",
    "- Your data is too large to fit in memory even grouped\n",
    "- You need low-latency stream processing\n",
    "- You‚Äôre working with tabular, relational data with well-defined schema\n",
    "\n",
    "## Summary\n",
    "\n",
    "- ‚úÖ Use `.materialize()` to safely reuse or inspect data\n",
    "- ‚ö†Ô∏è Remember: most inspection methods consume the stream\n",
    "- üß∞ Use `.pipe()` and `.head()` for debugging\n",
    "- üì¶ Prefer `.from_jsonl()` for scalable streaming input\n",
    "- üîÅ Fork or branch flows explicitly using `.materialize()` or `.fork()`\n",
    "\n",
    "Flow is designed to make pipelines simple, readable, and safe - as long as you‚Äôre mindful of when your data is being consumed.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
