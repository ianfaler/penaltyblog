{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fede8f2",
   "metadata": {},
   "source": [
    "# Processing Multiple Files in Parallel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10642325",
   "metadata": {},
   "source": [
    "If you have one data file per match or per day, you can use `folder_flow()` to apply a Flow pipeline across all files in parallel - speeding up your workflows on multi-core machines.\n",
    "\n",
    "## What `folder_flow` Does\n",
    "\n",
    "- Scans a folder for `.json` or `.jsonl` files\n",
    "- Loads each file into a Flow\n",
    "- Applies your function (`flow_fn`) to each one\n",
    "- Optionally:\n",
    "  - Writes output files (one per input)\n",
    "  - Or merges the results and reduces them with a final step\n",
    "\n",
    "### Example: Extract Shots and Save One File per Match\n",
    "\n",
    "```python\n",
    "from penaltyblog.matchflow import folder_flow, Flow\n",
    "\n",
    "def extract_shots(flow: Flow) -> Flow:\n",
    "    return (\n",
    "        flow\n",
    "        .filter(lambda r: r.get(\"type_name\") == \"Shot\")\n",
    "        .assign(is_goal=lambda r: r.get(\"shot_outcome\") == \"Goal\")\n",
    "        .select(\"match_id\", \"player_name\", \"shot_xg\", \"is_goal\")\n",
    "    )\n",
    "\n",
    "folder_flow(\n",
    "    input_folder=\"matches/\",\n",
    "    flow_fn=extract_shots,\n",
    "    output_folder=\"processed_matches/\"\n",
    ")\n",
    "```\n",
    "\n",
    "Each match file will be read, transformed, and saved using all your CPU cores.\n",
    "\n",
    "### Example: Merge All Files and Get Total Goals\n",
    "\n",
    "```python\n",
    "def count_goals(flow: Flow) -> Flow:\n",
    "    return flow.filter(lambda r: r.get(\"is_goal\")).summary(total_goals=\"count\")\n",
    "\n",
    "summary = folder_flow(\n",
    "    input_folder=\"matches/\",\n",
    "    flow_fn=extract_shots,\n",
    "    reduce_fn=count_goals\n",
    ")\n",
    "\n",
    "print(summary.collect())\n",
    "```\n",
    "\n",
    "## Guidelines for `folder_flow`\n",
    "\n",
    "| Parameter       | Description                                          |\n",
    "| --------------- | ---------------------------------------------------- |\n",
    "| `input_folder`  | Folder with your `.json` or `.jsonl` files           |\n",
    "| `flow_fn`       | Your pipeline for a single file (must return a Flow) |\n",
    "| `output_folder` | If given, saves output per file and returns nothing  |\n",
    "| `reduce_fn`     | Optional final step if combining all results         |\n",
    "| `n_jobs`        | Number of worker processes (default: all cores)      |\n",
    "\n",
    "### Tips & Gotchas\n",
    "\n",
    "- `flow_fn` and `reduce_fn` must be pickleable â†’ define them as regular named functions rather than lambda functions\n",
    "- Set `n_jobs=1` to debug errors more easily\n",
    "- Each file is processed independently (no shared state)\n",
    "\n",
    "## Summary\n",
    "\n",
    "Use `folder_flow()` to:\n",
    "\n",
    "- Scale up your analysis across many files\n",
    "- Split your work into smaller, parallel pieces\n",
    "- Save outputs or combine them flexibly\n",
    "\n",
    "Perfect for batched data like match events or lineups."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
