{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fede8f2",
   "metadata": {},
   "source": [
    "# Processing Multiple Files in Parallel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10642325",
   "metadata": {},
   "source": [
    "If your dataset is split across many files - one per match, gameweek, or team - you can use `folder_flow()` to apply a **Flow** pipeline to each file in parallel. This takes advantage of multiple CPU cores and makes your analysis much faster at scale.\n",
    "\n",
    "## What `folder_flow` Does\n",
    "\n",
    "- Scans a folder for `.json` or `.jsonl` files\n",
    "- Loads each file into a Flow\n",
    "- Applies your function (`flow_fn`) to each one\n",
    "- Optionally:\n",
    "  - Writes transformed records to a per-file output folder\n",
    "  - Or combines all records and runs a final reduction step\n",
    "\n",
    "### Example 1: Extract Shots and Save One File per Match\n",
    "\n",
    "```python\n",
    "from penaltyblog.matchflow import folder_flow, Flow\n",
    "\n",
    "def extract_shots(flow: Flow) -> Flow:\n",
    "    return (\n",
    "        flow\n",
    "        .filter(lambda r: r.get(\"type_name\") == \"Shot\")\n",
    "        .assign(is_goal=lambda r: r.get(\"shot_outcome\") == \"Goal\")\n",
    "        .select(\"match_id\", \"player_name\", \"shot_xg\", \"is_goal\")\n",
    "    )\n",
    "\n",
    "folder_flow(\n",
    "    input_folder=\"matches/\",\n",
    "    flow_fn=extract_shots,\n",
    "    output_folder=\"processed_matches/\"\n",
    ")\n",
    "```\n",
    "\n",
    "This will:\n",
    "\n",
    "- Load each file in `matches/`\n",
    "- Extract only the shots\n",
    "- Save the transformed records to `processed_matches/<original_filename>.json`\n",
    "\n",
    "### Example 2: Merge All Files and Summarize Total Goals\n",
    "\n",
    "```python\n",
    "def count_goals(flow: Flow) -> Flow:\n",
    "    return flow.filter(lambda r: r.get(\"is_goal\")).summary(total_goals=\"count\")\n",
    "\n",
    "summary = folder_flow(\n",
    "    input_folder=\"matches/\",\n",
    "    flow_fn=extract_shots,\n",
    "    reduce_fn=count_goals\n",
    ")\n",
    "\n",
    "print(summary.collect())\n",
    "```\n",
    "\n",
    "This:\n",
    "\n",
    "- Runs `extract_shots()` on every file\n",
    "- Merges all results into a single Flow\n",
    "- Applies `count_goals()` as a final summary step\n",
    "\n",
    "## Parameters\n",
    "\n",
    "| Parameter       | Description                                            |\n",
    "| --------------- | ------------------------------------------------------ |\n",
    "| `input_folder`  | Folder with `.json` or `.jsonl` files                  |\n",
    "| `flow_fn`       | Your pipeline for a single file (must return a `Flow`) |\n",
    "| `output_folder` | If set, saves output per file; no results are returned |\n",
    "| `reduce_fn`     | Optional; run after merging results from all files     |\n",
    "| `n_jobs`        | Number of worker processes (default: all CPU cores)    |\n",
    "| `encoding`      | File encoding (default: `\"utf-8\"`)                     |\n",
    "\n",
    "## Output File Example\n",
    "\n",
    "```bash\n",
    "processed_matches/\n",
    "‚îú‚îÄ‚îÄ match1.json\n",
    "‚îú‚îÄ‚îÄ match2.json\n",
    "‚îú‚îÄ‚îÄ match3.json\n",
    "```\n",
    "\n",
    "Output file format depends on the input:\n",
    "\n",
    "- `.jsonl` input ‚Üí writes `.jsonl` file\n",
    "- `.json` input ‚Üí writes `.json` array\n",
    "\n",
    "Use consistent extensions to control format.\n",
    "\n",
    "### Tips & Gotchas\n",
    "\n",
    "- ‚úÖ `flow_fn` and `reduce_fn` must be pickleable - use regular named functions (not lambdas or closures).\n",
    "- üß™ Use `n_jobs=1` during development to debug more easily.\n",
    "- üì¶ Each file is processed independently - no shared state.\n",
    "- ‚ùå You can't use non-pickleable libraries like open file handles or class-bound methods inside `flow_fn`.\n",
    "\n",
    "## Summary\n",
    "\n",
    "Use `folder_flow()` when:\n",
    "\n",
    "- You want to scale your analysis across hundreds of files\n",
    "- You need fast, parallelized processing\n",
    "- You want to either:\n",
    "  - Save per-file results\n",
    "  - Merge them into a final summary\n",
    "\n",
    "It‚Äôs perfect for event data, lineups, match summaries, or anything split into multiple files."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
