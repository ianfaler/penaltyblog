{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d49ebd83",
   "metadata": {},
   "source": [
    "# Utility, Inspection, & Interoperability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5074ba",
   "metadata": {},
   "source": [
    "Beyond transforming data, `Flow` provides several utility methods to help you inspect your data stream, understand its contents, and integrate `Flow` pipelines with other Python libraries and custom functions.\n",
    "\n",
    "## Inspecting Your Flow\n",
    "\n",
    "These methods help you peek into your `Flow` without necessarily processing the entire stream (though some, like `last()` or `len()`, do need to consume it).\n",
    "\n",
    "### Getting the First Record (`.first()`)\n",
    "\n",
    "`first()` returns the very first record (dictionary) from the `Flow` without consuming it from the `Flow` itself for subsequent operations. If the `Flow` is empty, it returns `None`.\n",
    "\n",
    "```python\n",
    "first_event = events_flow.first()\n",
    "```\n",
    "\n",
    "This is useful for quickly checking the structure of your records or grabbing a sample value.\n",
    "\n",
    "### Getting the Last Record (`.last()`)\n",
    "\n",
    "`last()` returns the very last record (dictionary) from the `Flow`.\n",
    "\n",
    "**Important**: To find the last record, this method must iterate through and consume the entire `Flow`. The `Flow` instance it's called on will be exhausted afterwards. If the `Flow` is empty, it returns `None`.\n",
    "\n",
    "```python\n",
    "last_event_in_match = events_flow.last() # events_flow is now exhausted\n",
    "if last_event_in_match:\n",
    "    print(f\"The last event timestamp was: {last_event_in_match.get('timestamp')}\")\n",
    "```\n",
    "\n",
    "### Checking if a Flow is Empty (`.is_empty()`)\n",
    "\n",
    "`is_empty()` returns `True` if the `Flow` contains no records, and `False` otherwise. This method attempts to check for the first record without consuming it for subsequent operations if the flow is not empty.\n",
    "\n",
    "### Discovering Record Keys (`.keys()`)\n",
    "\n",
    "`keys(limit=None)` returns a set of all unique field names (keys) found across the records in the Flow.\n",
    "\n",
    "- By default (limit=None), it inspects all records, which will consume the `Flow`.\n",
    "- If limit is set to an integer (e.g., limit=100), it only inspects the first limit records. In this case, the `Flow`'s internal iterator is advanced past these limit records for subsequent operations, but the rest of the stream remains. The method attempts to do this without consuming the inspected part from the main `Flow` object for later full iteration.\n",
    "\n",
    "```python\n",
    "# Get all keys from the first 10 records without consuming the whole flow for other uses\n",
    "sample_keys = events_flow.keys(limit=10)\n",
    "print(f\"Keys found in the first 10 records: {sample_keys}\")\n",
    "\n",
    "# Get all keys from all records (consumes events_flow)\n",
    "all_possible_keys = events_flow.keys()\n",
    "print(f\"All keys found in the dataset: {all_possible_keys}\")\n",
    "```\n",
    "\n",
    "This is very useful for understanding the schema of your data, especially if it varies between records.\n",
    "\n",
    "### Getting the Length of a Flow (`len()`)\n",
    "\n",
    "You can use the built-in `len(my_flow)` function to count the number of records in a Flow.\n",
    "\n",
    "**Important**: To count all records, `len()` must iterate through and consume the entire `Flow`. The `Flow` instance will be exhausted afterwards.\n",
    "\n",
    "```python\n",
    "number_of_events = len(events_flow) \n",
    "print(f\"Total number of events: {number_of_events}\")\n",
    "```\n",
    "\n",
    "### String Representation (`__repr__()`)\n",
    "\n",
    "When you print a `Flow` object or inspect it in an interactive session, its `__repr__` method provides a summary:\n",
    "\n",
    "```python\n",
    "print(events_flow)\n",
    "# Output might look like:\n",
    "# <Penaltyblog Flow | n≈? | sample=[{'id': 1, ...}, {'id': 2, ...}, {'id': 3, ...}]>\n",
    "# Or if len() was called before:\n",
    "# <Penaltyblog Flow | n≈1500 | sample=[{'id': 1, ...}, {'id': 2, ...}, {'id': 3, ...}]>\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16576321",
   "metadata": {},
   "source": [
    "## Materializing the Flow\n",
    "\n",
    "### Collecting All Records (`.collect()`)\n",
    "\n",
    "We've used this throughout: `my_flow.collect()` processes the entire planned pipeline and returns a Python list of all the resulting dictionaries. This is the primary way to get all your processed data into memory if needed.\n",
    "\n",
    "This, by definition, consumes the `Flow`.\n",
    "\n",
    "```python\n",
    "processed_records_list = events_flow.filter(...).assign(...).collect()\n",
    "```\n",
    "\n",
    "### Extending Flow with Custom Logic (`.pipe()`)\n",
    "\n",
    "The `.pipe(func, *args, **kwargs)` method allows you to insert your own custom functions (or functions from other libraries) into a `Flow` chain. The `Flow` object itself is passed as the first argument to your function, followed by any additional *args and **kwargs you provide.\n",
    "\n",
    "Your function should typically return a `Flow` object if you want to continue chaining `Flow` methods, but it can return anything (e.g., a pandas DataFrame, a plot, a custom summary).\n",
    "\n",
    "### Example: A custom function to filter and assign in one step\n",
    "\n",
    "```python\n",
    "def process_shots_custom(flow_object, min_xg=0.25):\n",
    "    return (\n",
    "        flow_object\n",
    "        .filter(lambda r: r.get(\"type_name\") == \"Shot\" and r.get(\"shot_xg\", 0) >= min_xg)\n",
    "        .assign(is_high_xg=True)\n",
    "    )\n",
    "\n",
    "high_xg_shots_flow = Flow(events).pipe(process_shots_custom, min_xg=0.25)\n",
    "\n",
    "# Now you can continue chaining on high_xg_shots_flow or collect it:\n",
    "result = high_xg_shots_flow.select(\"player_name\", \"shot_xg\", \"is_high_xg\").collect()\n",
    "```\n",
    "\n",
    "### Example: Piping to a pandas function after converting\n",
    "\n",
    "```python\n",
    "def calculate_team_summary_with_pandas(flow_object):\n",
    "    df = flow_object.to_pandas()\n",
    "    # Now use pandas for more complex grouping/aggregation if needed\n",
    "    return df.groupby(\"team_name\")[\"shot_xg\"].agg([\"sum\", \"mean\", \"count\"])\n",
    "\n",
    "team_xg_summary_df = (\n",
    "    events_flow.filter(lambda r: r.get(\"type_name\") == \"Shot\")\n",
    "    .pipe(calculate_team_summary_with_pandas)\n",
    ")\n",
    "print(team_xg_summary_df)\n",
    "```\n",
    "\n",
    "`.pipe()` is extremely powerful for integrating bespoke logic or leveraging functionalities from other libraries within your `Flow` pipeline.\n",
    "\n",
    "\n",
    "## Interoperability with Pandas\n",
    "\n",
    "Pandas is a cornerstone of data analysis in Python. `Flow` provides easy ways to move data to and from pandas DataFrames.\n",
    "\n",
    "### Converting to a Pandas DataFrame (`.to_pandas()`)\n",
    "\n",
    "As seen in the previous section on IO, `.to_pandas()` consumes the `Flow` and returns a pandas DataFrame.\n",
    "\n",
    "```python\n",
    "df_events = Flow(events).filter(lambda r: r.get(\"period\") == 1).to_pandas()\n",
    "print(df_events.info())\n",
    "```\n",
    "\n",
    "### Generating Descriptive Statistics (`.describe()`)\n",
    "\n",
    "`.describe(percentiles=..., include=..., exclude=...)` consumes the `Flow`, converts it to a pandas DataFrame internally, and then calls the DataFrame's `.describe()` method, returning a pandas DataFrame with summary statistics.\n",
    "\n",
    "```python\n",
    "# Assuming shots_flow contains only shot events\n",
    "numeric_shot_stats = shots_flow.select(\n",
    "    \"shot_statsbomb_xg\", \"shot_end_location_x\", \"shot_end_location_y\") \\\n",
    "                              .describe()\n",
    "print(numeric_shot_stats)\n",
    "\n",
    "# Describe specific columns or dtypes\n",
    "all_event_description = events_flow.describe(include='object') # Describe object/string columns\n",
    "```\n",
    "\n",
    "This is a quick way to get an overview of your data's distribution, similar to pandas.DataFrame.describe().\n",
    "\n",
    "These utility and interoperability methods make `Flow` a more complete and practical tool. They allow you to understand your data at various stages, customize processing with your own logic, and seamlessly integrate with the broader Python data science ecosystem, especially pandas. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d12297",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
