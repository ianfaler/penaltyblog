{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d49ebd83",
   "metadata": {},
   "source": [
    "# Utility, Inspection, & Interoperability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5074ba",
   "metadata": {},
   "source": [
    "Beyond transforming data, **Flow** provides several tools to help you inspect, debug, and connect your pipelines to other libraries like pandas - all while preserving the lazy, composable nature of your workflow.\n",
    "\n",
    "\n",
    "## Inspecting Your Flow\n",
    "\n",
    "`Flow` includes methods for peeking into the stream, checking fields, or verifying structure. Note: most of these methods consume the stream, meaning you cannot reuse the same flow afterward unless you‚Äôve explicitly materialized it.\n",
    "\n",
    "### `.first()`: Peek at the First Record\n",
    "\n",
    "Returns the first record in the stream. If the stream is empty, returns `None`.\n",
    "\n",
    "```python\n",
    "first_event = events_flow.first()\n",
    "```\n",
    "\n",
    "‚ö†Ô∏è This materializes the full stream via `.collect()`, so `events_flow` is now empty afterward. Use `.head(1)` for a shallow preview instead.\n",
    "\n",
    "### `.last()`: Get the Final Record\n",
    "\n",
    "```python\n",
    "last_event = events_flow.last()\n",
    "```\n",
    "\n",
    "Also calls `.collect()`, consuming the entire stream.\n",
    "\n",
    "### `.head(n)`: Safe Preview\n",
    "\n",
    "Get the first `n` records without consuming the full stream.\n",
    "\n",
    "```python\n",
    "Flow(data).head(3).collect()\n",
    "```\n",
    "\n",
    "‚úÖ Best choice for inspecting safely - consumes only the first `n` records.\n",
    "\n",
    "### `.is_empty()`: Check for Records\n",
    "\n",
    "```python\n",
    "if events_flow.is_empty():\n",
    "    print(\"No events found.\")\n",
    "```\n",
    "\n",
    "‚ö†Ô∏è This materializes the full stream via .collect().\n",
    "\n",
    "### `.keys(limit=None)`: Discover Field Names\n",
    "\n",
    "Returns the union of all keys across up to limit records.\n",
    "\n",
    "```python\n",
    "events_flow.keys(limit=10)\n",
    "events_flow.keys()      \n",
    "```\n",
    "\n",
    "Helpful for exploring semi-structured or nested JSON.\n",
    "\n",
    "‚ö†Ô∏è This also materializes the stream - use `.head().collect()` if you only need a preview.\n",
    "\n",
    "### `.len()`: Count the Records\n",
    "\n",
    "Internally calls `.collect()` - flow is consumed. If you want a new reusable flow, call `.materialize()` first:\n",
    "\n",
    "```python\n",
    "flow = Flow(data)\n",
    "materialized = flow.materialize()\n",
    "print(len(materialized))           # safe\n",
    "print(materialized.first())        # safe\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16576321",
   "metadata": {},
   "source": [
    "## Materializing the Flow\n",
    "\n",
    "### `.collect()`: Get All Records as a List\n",
    "\n",
    "```python\n",
    "records = events_flow.filter(...).assign(...).collect()\n",
    "```\n",
    "\n",
    "- Consumes the stream.\n",
    "- Returns a list of dicts.\n",
    "\n",
    "### `.materialize()`: Create a Reusable Flow\n",
    "\n",
    "```python\n",
    "f2 = events_flow.materialize()\n",
    "```\n",
    "\n",
    "- Also consumes the stream.\n",
    "- Returns a new `Flow` backed by a list - safe for reuse and inspection.\n",
    "\n",
    "## Forking a Flow: `.fork()`\n",
    "\n",
    "Sometimes you want to branch a `Flow` into two different pipelines - for example, to compute two different summaries from the same source. `.fork()` gives you two independent one-shot `Flows` from the same stream.\n",
    "\n",
    "```python\n",
    "flow1, flow2 = flow.fork()\n",
    "\n",
    "summary1 = flow1.filter(...).summary(...)\n",
    "summary2 = flow2.filter(...).summary(...)\n",
    "```\n",
    "\n",
    "üí° This does not materialize the stream into memory. It uses internal teeing, so each branch can only be used once. If you need a reusable copy, use `.materialize()` instead.\n",
    "\n",
    "### When to Use `.fork()`\n",
    "\n",
    "- You want to branch without collecting everything into memory\n",
    "- You know each fork will be used exactly once\n",
    "- You want to avoid `.materialize()` for memory reasons\n",
    "\n",
    "### When Not to Use It\n",
    "\n",
    "- You plan to reuse or inspect the flows multiple times ‚Üí use `.materialize()`\n",
    "- You want to store or debug intermediate steps ‚Üí `.collect()` or `.pipe()` is better\n",
    "\n",
    "## Custom Logic and Pipelines\n",
    "\n",
    "### `.pipe()`: Insert Your Own Function\n",
    "\n",
    "Plug in custom functions to extend or encapsulate logic:\n",
    "\n",
    "```python\n",
    "def process_shots(flow, min_xg=0.25):\n",
    "    return (\n",
    "        flow\n",
    "        .filter(lambda r: r.get(\"type_name\") == \"Shot\" and r.get(\"shot_xg\", 0) >= min_xg)\n",
    "        .assign(is_high_xg=True)\n",
    "    )\n",
    "\n",
    "# Chain your custom step using .pipe\n",
    "high_xg = Flow(events).pipe(process_shots, min_xg=0.3)\n",
    "results = high_xg.select(\"player_name\", \"shot_xg\", \"is_high_xg\").collect()\n",
    "```\n",
    "\n",
    "üí° If your function returns a `Flow`, you can keep chaining. If it returns something else (e.g., DataFrame), the pipeline ends there.\n",
    "\n",
    "### Use `.pipe()` with External Tools\n",
    "\n",
    "You can bridge into pandas (or anything else) via `.pipe()`:\n",
    "\n",
    "```python\n",
    "def team_summary(flow):\n",
    "    df = flow.to_pandas()\n",
    "    return df.groupby(\"team_name\")[\"shot_xg\"].agg([\"sum\", \"mean\", \"count\"])\n",
    "\n",
    "summary_df = (\n",
    "    Flow(events)\n",
    "    .filter(lambda r: r.get(\"type_name\") == \"Shot\")\n",
    "    .pipe(team_summary)\n",
    ")\n",
    "```\n",
    "\n",
    "## Interoperability with pandas\n",
    "\n",
    "### `.to_pandas()`: Convert to DataFrame\n",
    "\n",
    "```python\n",
    "df = Flow(events).filter(lambda r: r.get(\"period\") == 1).to_pandas()\n",
    "print(df.head())\n",
    "```\n",
    "\n",
    "- Materializes the `Flow`\n",
    "- Returns a pandas DataFrame\n",
    "\n",
    "### `.describe()`: Summary Stats\n",
    "\n",
    "Returns `pandas.DataFrame.describe()` on the full `Flow`.\n",
    "\n",
    "```python\n",
    "Flow(events)\n",
    "  .select(\"shot_xg\", \"location_x\", \"location_y\")\n",
    "  .describe()\n",
    "```\n",
    "\n",
    "Supports typical pandas `.describe()` args:\n",
    "\n",
    "```python\n",
    "# Show object/string field summaries\n",
    "Flow(events).describe(include=\"object\")\n",
    "\n",
    "# Change percentiles\n",
    "Flow(events).describe(percentiles=(0.1, 0.5, 0.9))\n",
    "```\n",
    "\n",
    "### Summary\n",
    "\n",
    "These utility methods let you:\n",
    "\n",
    "- ‚úÖ Inspect flows (`.first()`, `.keys()`, `.head()`)\n",
    "- ‚úÖ Materialize your data for reuse (`.collect()`, `.materialize()`)\n",
    "- ‚úÖ Debug and branch with `.pipe()`\n",
    "- ‚úÖ Export to pandas with `.to_pandas()` and `.describe()`\n",
    "\n",
    "‚ö†Ô∏è Many inspection methods consume the flow. If you need to reuse the data, use `.materialize()` to create a repeatable copy.\n",
    "\n",
    "## What‚Äôs Next?\n",
    "\n",
    "Next, we‚Äôll look at best practices for writing clean, maintainable `Flow` pipelines and working efficiently with large datasets."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
